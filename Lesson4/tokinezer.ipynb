{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f130fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=\"text.txt\",\n",
    "    model_prefix=\"spm_tokenizer\",\n",
    "    vocab_size=64,\n",
    "    model_type=\"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08970a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9, 16, 18, 39, 55, 47, 41, 44, 49, 43, 10, 32, 41, 47, 26],\n",
       " 'the capital of france is paris')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_tokenizer = spm.SentencePieceProcessor(model_file=\"spm_tokenizer.model\")\n",
    "\n",
    "text1 = \"the capital of france is paris\"\n",
    "spm_ids = spm_tokenizer.Encode(text1)\n",
    "spm_tokens = spm_tokenizer.Decode(spm_ids)\n",
    "spm_ids, spm_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f5b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tokenizers in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.22.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tokenizers) (0.35.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\iremm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7e6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1758de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hugging Face Tokenizer nesnesi oluşturuluyor. BPE (Byte-Pair Encoding) algoritması kullanılacak.\n",
    "hf_tokenizer = Tokenizer(BPE())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ddd98fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hf_tokenizer.get_vocab_size()  # Başlangıçta kelime dağarcığı boş, bu yüzden 0 döner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2c40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer'ın kelimeleri ayırmak için Whitespace (boşluk) tabanlı ön-tokenizer kullanmasını sağlar.\n",
    "hf_tokenizer.pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70aa60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BpeTrainer ile tokenizer'ın kelime dağarcığını (vocab) oluşturması sağlanır.\n",
    "# vocab_size=64 ile toplam 64 adet token oluşturulacak.\n",
    "# special_tokens ile özel tokenlar (örneğin bilinmeyen kelimeler için <unk>) eklenir.\n",
    "trainer = BpeTrainer(vocab_size=64, special_tokens=[\"<unk>\"])\n",
    "\n",
    "# hf_tokenizer.train ile \"text.txt\" dosyasındaki veriler kullanılarak tokenizer eğitilir.\n",
    "hf_tokenizer.train([\"text.txt\"], trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1d5772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, [7, 13, 13, 16, 1, 14, 24, 6, 16, 9, 26, 5, 22, 21, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.get_vocab_size(), hf_tokenizer.encode(\"Hello, my dog is cute\").ids  # Eğitildikten sonra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f1348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_tokenizer.save(\"hf_tokenizer.json\")  # Tokenizer'ı JSON formatında kaydeder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08fa9b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iremm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 13, 13, 16, 1, 14, 24, 6, 16, 9, 26, 5, 22, 21, 7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"hf_tokenizer.json\")\n",
    "\n",
    "fast_tokenizer.encode(\"Hello, my dog is cute\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
